<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>QML Vietnam</title>
    <link>https://example.com/</link>
      <atom:link href="https://example.com/index.xml" rel="self" type="application/rss+xml" />
    <description>QML Vietnam</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Sat, 29 Oct 2022 14:54:53 +0700</lastBuildDate>
    <image>
      <url>https://example.com/media/icon_hu03ccfb93536ffaa14d5c51dca71785c3_35563_512x512_fill_lanczos_center_3.png</url>
      <title>QML Vietnam</title>
      <link>https://example.com/</link>
    </image>
    
    <item>
      <title>Octorber 2022</title>
      <link>https://example.com/newsletter/octorber-2022/</link>
      <pubDate>Sat, 29 Oct 2022 14:54:53 +0700</pubDate>
      <guid>https://example.com/newsletter/octorber-2022/</guid>
      <description>&lt;h1 id=&#34;news-&#34;&gt;News üì∞&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://www.nature.com/articles/s41598-022-21607-4&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Determinable and interpretable network representation for link prediction&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://cloudblogs.microsoft.com/quantum/2022/10/20/azure-quantum-credits-program-propels-quantum-innovation-and-exploration-for-researchers-educators-and-students/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Azure Quantum Credits Program propels quantum innovation and exploration for researchers, educators, and students&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://www.eurekalert.org/news-releases/969327&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Penn State researchers to explore using quantum computers to design new drugs&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://www.einnews.com/pr_news/597582546/multiverse-computing-and-mila-join-forces-to-advance-artificial-intelligence-with-quantum-computing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Multiverse Computing and Mila Join Forces to Advance Artificial Intelligence with Quantum Computing&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://www.tribuneindia.com/news/brand-connect/quantum-ai-elon-musk-review-scam-app-or-legit-444921&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Quantum AI Elon Musk Review / Scam App Or Legit?&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&#34;videos-&#34;&gt;Videos üìΩÔ∏è&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=NqHKr9CGWJ0&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Quantum Machine Learning Explained&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=gyU5tIppmIk&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Qiskit Falll Fest CIC-IPN Mexico 2022- Quantum Machine Learning&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=zqxCnDcGSgQ&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Quantum Machine Learning Neuroimaging for Alzheimer‚Äôs Disease&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=6Mo0EQ7bOpg&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;MLBBQ: Quantum Machine Learning by Pavel Popov&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=x6oLsJtxWzs&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Quantum Machine Learning: Opportunities and Challenges&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=2rJFsxcM0N4&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Hands-on quantum machine learning | Rodrigo Morales | ADC2022&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=CDCiQdtOhLY&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;‚ÄúReinforcement Learning for Quantum Technologies,‚Äù presented by Florian Marquardt&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&#34;publications-&#34;&gt;Publications üìÉ&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2210.07980&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Representation Theory for Geometric Quantum Machine Learning&lt;/a&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-0&#34;&gt;
  &lt;summary&gt;Abstract:&lt;/summary&gt;
  &lt;p&gt;&lt;blockquote&gt;
&lt;p&gt;Recent advances in classical machine learning have shown that creating models with inductive biases encoding the symmetries of a problem can greatly improve performance. Importation of these ideas, combined with an existing rich body of work at the nexus of quantum theory and symmetry, has given rise to the field of Geometric Quantum Machine Learning (GQML). Following the success of its classical counterpart, it is reasonable to expect that GQML will play a crucial role in developing problem-specific and quantum-aware models capable of achieving a computational advantage. Despite the simplicity of the main idea of GQML &amp;ndash; create architectures respecting the symmetries of the data &amp;ndash; its practical implementation requires a significant amount of knowledge of group representation theory. We present an introduction to representation theory tools from the optics of quantum learning, driven by key examples involving discrete and continuous groups. These examples are sewn together by an exposition outlining the formal capture of GQML symmetries via &amp;ldquo;label invariance under the action of a group representation&amp;rdquo;, a brief (but rigorous) tour through finite and compact Lie group representation theory, a reexamination of ubiquitous tools like Haar integration and twirling, and an overview of some successful strategies for detecting symmetries.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/p&gt;
&lt;/details&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2210.08566&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Theory for Equivariant Quantum Neural Networks&lt;/a&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-1&#34;&gt;
  &lt;summary&gt;Abstract:&lt;/summary&gt;
  &lt;p&gt;&lt;blockquote&gt;
&lt;p&gt;Most currently used quantum neural network architectures have little-to-no inductive biases, leading to trainability and generalization issues. Inspired by a similar problem, recent breakthroughs in classical machine learning address this crux by creating models encoding the symmetries of the learning task. This is materialized through the usage of equivariant neural networks whose action commutes with that of the symmetry. In this work, we import these ideas to the quantum realm by presenting a general theoretical framework to understand, classify, design and implement equivariant quantum neural networks. As a special implementation, we show how standard quantum convolutional neural networks (QCNN) can be generalized to group-equivariant QCNNs where both the convolutional and pooling layers are equivariant under the relevant symmetry group. Our framework can be readily applied to virtually all areas of quantum machine learning, and provides hope to alleviate central challenges such as barren plateaus, poor local minima, and sample complexity.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/p&gt;
&lt;/details&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2210.09974&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Theoretical Guarantees for Permutation-Equivariant Quantum Neural Networks&lt;/a&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-2&#34;&gt;
  &lt;summary&gt;Abstract:&lt;/summary&gt;
  &lt;p&gt;&lt;blockquote&gt;
&lt;p&gt;Despite the great promise of quantum machine learning models, there are several challenges one must overcome before unlocking their full potential. For instance, models based on quantum neural networks (QNNs) can suffer from excessive local minima and barren plateaus in their training landscapes. Recently, the nascent field of geometric quantum machine learning (GQML) has emerged as a potential solution to some of those issues. The key insight of GQML is that one should design architectures, such as equivariant QNNs, encoding the symmetries of the problem at hand. Here, we focus on problems with permutation symmetry (i.e., the group of symmetry Sn), and show how to build Sn-equivariant QNNs. We provide an analytical study of their performance, proving that they do not suffer from barren plateaus, quickly reach overparametrization, and can generalize well from small amounts of data. To verify our results, we perform numerical simulations for a graph state classification task. Our work provides the first theoretical guarantees for equivariant QNNs, thus indicating the extreme power and potential of GQML.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/p&gt;
&lt;/details&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://arxiv.org/pdf/2210.13442.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Protocols for classically training quantum generative models on probability distributions&lt;/a&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-3&#34;&gt;
  &lt;summary&gt;Abstract:&lt;/summary&gt;
  &lt;p&gt;&lt;blockquote&gt;
&lt;p&gt;Quantum Generative Modelling (QGM) relies on preparing quantum states and generating samples from these states as hidden - or known - probability distributions. As distributions from some classes of quantum states (circuits) are inherently hard to sample classically, QGM represents an excellent testbed for quantum supremacy experiments. Furthermore, generative tasks are increasingly relevant for industrial machine learning applications, and thus QGM is a strong candidate for demonstrating a practical quantum advantage. However, this requires that quantum circuits are trained to represent industrially relevant distributions, and the corresponding training stage has an extensive training cost for current quantum hardware in practice. In this work, we propose protocols for classical training of QGMs based on circuits of the specific type that admit an efficient gradient computation, while remaining hard to sample. In particular, we consider Instantaneous Quantum Polynomial (IQP) circuits and their extensions. Showing their classical simulability in terms of the time complexity, sparsity and anti-concentration properties, we develop a classically tractable way of simulating their output probability distributions, allowing classical training to a target probability distribution. The corresponding quantum sampling from IQPs can be performed efficiently, unlike when using classical sampling. We numerically demonstrate the end-to-end training of IQP circuits using probability distributions for up to 30 qubits on a regular desktop computer. When applied to industrially relevant distributions this combination of classical training with quantum sampling represents an avenue for reaching advantage in the NISQ era.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/p&gt;
&lt;/details&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2210.11850&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Universal algorithms for quantum data learning&lt;/a&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-4&#34;&gt;
  &lt;summary&gt;Abstract:&lt;/summary&gt;
  &lt;p&gt;&lt;blockquote&gt;
&lt;p&gt;Operating quantum sensors and quantum computers would make data in the form of quantum states available for purely quantum processing, opening new avenues for studying physical processes and certifying quantum technologies. In this Perspective, we review a line of works dealing with measurements that reveal structural properties of quantum datasets given in the form of product states. These algorithms are universal, meaning that their performances do not depend on the reference frame in which the dataset is provided. Requiring the universality property implies a characterization of optimal measurements via group representation theory.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/p&gt;
&lt;/details&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2209.05523&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Generalization despite overfitting in quantum machine learning models&lt;/a&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-5&#34;&gt;
  &lt;summary&gt;Abstract:&lt;/summary&gt;
  &lt;p&gt;&lt;blockquote&gt;
&lt;p&gt;The widespread success of deep neural networks has revealed a surprise in classical machine learning: very complex models often generalize well while simultaneously overfitting training data. This phenomenon of benign overfitting has been studied for a variety of classical models with the goal of better understanding the mechanisms behind deep learning. Characterizing the phenomenon in the context of quantum machine learning might similarly improve our understanding of the relationship between overfitting, overparameterization, and generalization. In this work, we provide a characterization of benign overfitting in quantum models. To do this, we derive the behavior of a classical interpolating Fourier features models for regression on noisy signals, and show how a class of quantum models exhibits analogous features, thereby linking the structure of quantum circuits (such as data-encoding and state preparation operations) to overparameterization and overfitting in quantum models. We intuitively explain these features according to the ability of the quantum model to interpolate noisy data with locally &amp;ldquo;spiky&amp;rdquo; behavior and provide a concrete demonstration example of benign overfitting.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/p&gt;
&lt;/details&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2209.14353&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Interpretable Quantum Advantage in Neural Sequence Learning&lt;/a&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-6&#34;&gt;
  &lt;summary&gt;Abstract:&lt;/summary&gt;
  &lt;p&gt;&lt;blockquote&gt;
&lt;p&gt;Quantum neural networks have been widely studied in recent years, given their potential practical utility and recent results regarding their ability to efficiently express certain classical data. However, analytic results to date rely on assumptions and arguments from complexity theory. Due to this, there is little intuition as to the source of the expressive power of quantum neural networks or for which classes of classical data any advantage can be reasonably expected to hold. Here, we study the relative expressive power between a broad class of neural network sequence models and a class of recurrent models based on Gaussian operations with non-Gaussian measurements. We explicitly show that quantum contextuality is the source of an unconditional memory separation in the expressivity of the two model classes. Additionally, as we are able to pinpoint quantum contextuality as the source of this separation, we use this intuition to study the relative performance of our introduced model on a standard translation data set exhibiting linguistic contextuality. In doing so, we demonstrate that our introduced quantum models are able to outperform state of the art classical models even in practice.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/p&gt;
&lt;/details&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>B√†i 2: Quantum Squared-Distance Classifier</title>
      <link>https://example.com/post/example-1/</link>
      <pubDate>Tue, 11 Oct 2022 23:25:52 +0700</pubDate>
      <guid>https://example.com/post/example-1/</guid>
      <description>&lt;p&gt;Trong b√†i n√†y, m√¨nh ƒëi qua m·ªôt ph∆∞∆°ng ph√°p x·ª≠ l√Ω b√†i to√°n &lt;em&gt;nearest neighbour&lt;/em&gt; b·∫±ng thu·∫≠t to√°n quantum. B√†i vi·∫øt d∆∞·ªõi ƒë√¢y s·∫Ω d·ª±a v√†o b√†i b√°o g·ªëc: &lt;a href=&#34;https://arxiv.org/pdf/1703.10793.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Implementing a distance-based classifier with a quantum interference circuit&lt;/a&gt;, n·∫øu ai mu·ªën t√¨m hi·ªÉu s√¢u h∆°n v·ªÅ √Ω t∆∞·ªüng n√†y th√¨ c√≥ th·ªÉ gh√© qua.&lt;/p&gt;
&lt;h1 id=&#34;n·ªôi-dung&#34;&gt;N·ªôi dung&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;#1&#34;&gt;Squared-Distance Classifier&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#2&#34;&gt;Quantum Squared-Distance Classifier&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#3&#34;&gt;K·∫øt lu·∫≠n&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#4&#34;&gt;Source Code&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&#34;squared-distance-classifier-a-name1a&#34;&gt;Squared-Distance Classifier &lt;a name=&#34;1&#34;&gt;&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;·ªû ƒë√¢y, m√¨nh x√©t v√≠ d·ª• b√†i to√°n ph√¢n lo·∫°i t·∫≠p data &lt;a href=&#34;https://www.kaggle.com/c/titanic&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Titanic&lt;/a&gt;. Gi·∫£ s·ª≠ t·∫≠p data ƒë∆∞·ª£c bi·ªÉu di·ªÖn d∆∞·ªõi d·∫°ng:&lt;/p&gt;

$$
\mathcal{D} = \Big\{ ({\bf{x}}^1, y^1), \ldots ({\bf{x}}^M , y^M)  \Big\},
$$

&lt;p&gt;trong ƒë√≥ c√°c v√©c-t∆° ƒë·∫ßu v√†o 2 chi·ªÅu: ${ {\bf{x}}^m = ({x_0}^m, {x_1}^m)^T}, m = 1,2,&amp;hellip;,M$ t∆∞·ª£ng tr∆∞ng cho m·ªôt h√†nh kh√°ch tr√™n chuy·∫øn t√†u Titanic ƒë√£ b·ªã nh·∫•n ch√¨m v√†o nƒÉm 1912. Trong ƒë√≥ $x_0$ l√† gi√° v√© trong kho·∫£ng t·ª´ 0 ƒë·∫øn 10,000 ƒë√¥ la, v√† $x_1$ l√† s·ªë hi·ªáu cabin trong kho·∫£ng t·ª´ 1 ƒë·∫øn 2,500. ·ª®ng v·ªõi m·ªói m·ªôt v√©c-t∆° ƒë·∫ßu v√†o l√† nh√£n $y^m = {0,1}$ t∆∞∆°ng ·ª©ng ƒë·ªÉ ch·ªâ ra h√†nh kh√°ch ƒë√≥ ƒë√£ s·ªëng s√≥t hay kh√¥ng.&lt;/p&gt;
















&lt;figure  id=&#34;figure-soucehttpslinkspringercombook101007978-3-319-96424-9&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;[Souce](https://link.springer.com/book/10.1007/978-3-319-96424-9)&#34; srcset=&#34;
               /post/example-1/data_hu78303baaf7a0b85d6e4300342c9fda14_45037_631af45315bba8601596423120b56c6c.webp 400w,
               /post/example-1/data_hu78303baaf7a0b85d6e4300342c9fda14_45037_3666c6daa3fe241e15be294f70efc0e8.webp 760w,
               /post/example-1/data_hu78303baaf7a0b85d6e4300342c9fda14_45037_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://example.com/post/example-1/data_hu78303baaf7a0b85d6e4300342c9fda14_45037_631af45315bba8601596423120b56c6c.webp&#34;
               width=&#34;760&#34;
               height=&#34;183&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      &lt;a href=&#34;https://link.springer.com/book/10.1007/978-3-319-96424-9&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Souce&lt;/a&gt;
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;N·∫øu t·ª´ng t√¨m hi·ªÉu qua v·ªÅ Machine Learning, ch·∫Øc h·∫≥n c√°c b·∫°n ƒë√£ nghe ho·∫∑c ƒë·ªçc qua v·ªÅ thu·∫≠t to√°n &lt;em&gt;nearest neighbour&lt;/em&gt;: v·ªõi m·ªói v√©c-t∆° ƒë·∫ßu v√†o m·ªõi, th√¨ nh√£n c·ªßa n√≥ s·∫Ω ƒë∆∞·ª£c quy·∫øt ƒë·ªãnh b·ªüi ƒëi·ªÉm d·ªØ li·ªáu g·∫ßn nh·∫•t v·ªõi n√≥. C√≥ nhi·ªÅu c√°ch ƒë·ªÉ x√°c ƒë·ªãnh nh·ªØng ƒëi·ªÉm d·ªØ li·ªáu g·∫ßn nh·∫•t ƒë√≥ nh∆∞ng ph·ªï bi·∫øn l√† &lt;a href=&#34;https://en.wikipedia.org/wiki/Euclidean_distance&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Euclidean distance&lt;/a&gt;. Do v·∫≠y, ta c√≥ c√°ch t√≠nh h·ªá s·ªë cho vi·ªác g√°n nh√£n v√©c-t∆° $\tilde{x}$ m·ªõi theo nh√£n c·ªßa $x^m$:

$$
\gamma_m = 1-\frac{1}{c}|\tilde{{\bf x}}-{\bf x}^m|^2, 
$$

trong ƒë√≥ $c$ l√† h·∫±ng s·ªë. H·ªá s·ªë c√†ng cao ch·ª©ng t·ªè $\tilde{{\bf x}}$ c√†ng g·∫ßn $x^m$. G·ªçi $\tilde{y}$ l√† nh√£n ƒë∆∞·ª£c g√°n cho $\tilde{{\bf x}}$, ta c√≥ x√°c xu·∫•t $p_{\tilde{{\bf x}}}(\tilde{y}=1)$ l√† t·ªïng trung b√¨nh h·ªá s·ªë c·ªßa $M_1$ ƒëi·ªÉm d·ªØ li·ªáu m√† c√≥ nh√£n l√† $1$:

$$
p_{\tilde{{\bf x}}}(\tilde{y}=1) = \frac{1}{\chi}\frac{1}{M_1} \sum_{m|y^m=1}(1-\frac{1}{c}|\tilde{{\bf x}}-{\bf x}^m|^2) 
$$

T∆∞∆°ng t·ª± nh∆∞ v·∫≠y,  $p_{\tilde{{\bf x}}}(\tilde{y}=0)$ l√† t·ªïng trung b√¨nh h·ªá s·ªë c·ªßa c√°c ƒëi·ªÉm d·ªØ li·ªáu m√† c√≥ nh√£n l√† $0$. Trong ƒë√≥ $\frac{1}{\chi}$ l√† &lt;em&gt;normalizing factor&lt;/em&gt; sao cho $p_{\tilde{{\bf x}}}(\tilde{y}=0)+p_{\tilde{{\bf x}}}(\tilde{y}=1)=1$.&lt;/p&gt;
















&lt;figure  id=&#34;figure-soucehttpslinkspringercombook101007978-3-319-96424-9&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;[Souce](https://link.springer.com/book/10.1007/978-3-319-96424-9)&#34; srcset=&#34;
               /post/example-1/visualization_hu16f5b777f6d9f46571da58af462c2aaf_44927_fe9e1f90176d7b9290d6772978090665.webp 400w,
               /post/example-1/visualization_hu16f5b777f6d9f46571da58af462c2aaf_44927_96d167ef3597b0fad12f14d6ffd877df.webp 760w,
               /post/example-1/visualization_hu16f5b777f6d9f46571da58af462c2aaf_44927_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://example.com/post/example-1/visualization_hu16f5b777f6d9f46571da58af462c2aaf_44927_fe9e1f90176d7b9290d6772978090665.webp&#34;
               width=&#34;760&#34;
               height=&#34;263&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      &lt;a href=&#34;https://link.springer.com/book/10.1007/978-3-319-96424-9&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Souce&lt;/a&gt;
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;√Åp d·ª•ng ph∆∞∆°ng ph√°p ta th·∫•y &lt;em&gt;Passenger 3&lt;/em&gt; s·∫Ω g·∫ßn v·ªõi &lt;em&gt;Passenger 1&lt;/em&gt; h∆°n so v·ªõi &lt;em&gt;Passenger 2&lt;/em&gt; (Fig 1.2), v√† m√¥ h√¨nh s·∫Ω ƒë∆∞a ra d·ª± ƒëo√°n l√† $1$ t∆∞∆°ng ·ª©ng v·ªõi &lt;em&gt;survival&lt;/em&gt;.&lt;/p&gt;
&lt;h1 id=&#34;quantum-squared-distance-classifier-a-name2a&#34;&gt;Quantum Squared-Distance Classifier &lt;a name=&#34;2&#34;&gt;&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;Gi·ªù h√£y x·ª≠ l√Ω b√†i to√†n n√†y b·∫±ng ph∆∞∆°ng ph√°p &amp;lsquo;quantum&amp;rsquo;.&lt;/p&gt;
&lt;h2 id=&#34;b∆∞·ªõc-1-data-preprocessing-and-encoding&#34;&gt;B∆∞·ªõc 1: Data preprocessing and Encoding&lt;/h2&gt;
&lt;p&gt;ƒê·∫ßu ti√™n ch√∫ng ta s·∫Ω ƒëi t·ªõi m·ªôt c√¢u h·ªèi kinh ƒëi·ªÉn &amp;ldquo;L√†m sao c√≥ th·ªÉ bi·ªÉu di·ªÖn d·ªØ li·ªáu tr√™n m√°y t√≠nh l∆∞·ª£ng t·ª≠?&amp;rdquo;. N·∫øu nh∆∞ tr√™n m√°y t√≠nh truy·ªÅn th·ªëng c√°c th√¥ng tin nh∆∞ ·∫£nh s·∫Ω th∆∞·ªùng ƒë∆∞·ª£c bi·ªÉn di·ªÖn tr√™n kh√¥ng gian RBG c√≥ gi√° tr·ªã t·ª´ 0 ƒë·∫øn 255, hay ch√∫ng ta c√≥ &lt;a href=&#34;https://en.wikipedia.org/wiki/Word_embedding&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Word Embedding&lt;/a&gt; ƒë·ªÉ bi·ªÉu th√¥ng tin d·∫°ng vƒÉn b·∫£n th√†nh c√°c v√©c-t∆°, th√¨ v·∫•n ƒë·ªÅ c·ªßa c√°c thu·∫≠t to√°n l∆∞·ª£ng t·ª≠ c≈©ng nh∆∞ v·∫≠y. Th·ª±c ch·∫•t, ch·ªß ƒë·ªÅ v·ªÅ vi·ªác m√£ h√≥a th√¥ng tin tr√™n kh√¥ng gian l∆∞·ª£ng t·ª≠ (&lt;em&gt;Quantum Embedding&lt;/em&gt;) v·∫´n ƒëang ƒë∆∞·ª£c c·ªông ƒë·ªìng nghi√™n c·ª©u quan t√¢m ƒë·∫∑c bi·ªát trong lƒ©nh v·ª±c Quantum Machine Learning. N·∫øu c√°c b·∫°n quan t√¢m ƒë·∫øn ch·ªß ƒë·ªÅ n√†y c√≥ th·ªÉ xem qua &lt;a href=&#34;https://arxiv.org/abs/2001.03622&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;paper&lt;/a&gt; n√†y ƒë·ªÉ bi·∫øt r√µ h∆°n v·ªÅ c√°c c√°ch m√£ th√¥ng tin trong QML v√† s·ª± quan tr·ªçng c·ªßa n√≥. M√¨nh s·∫Ω l√†m m·ªôt b√†i vi·∫øt chi ti·∫øt h∆°n v·ªÅ ch·ªß ƒë·ªÅ n√†y trong t∆∞∆°ng lai.&lt;/p&gt;
&lt;p&gt;Quay l·∫°i v·ªõi b√†i to√°n c·ªßa ch√∫ng ta, m√¨nh s·∫Ω √°p d·ª•ng m·ªôt ph∆∞∆°ng ph√°p g·ªçi l√† &lt;em&gt;Amplitude Embedding&lt;/em&gt; - m·ªôt ph∆∞∆°ng ph√°p r·∫•t ph·ªë bi·∫øn trong QML: Cho $X \in \mathbb{R}^N$ l√† m·ªôt v√©c-t∆° ƒë∆°n nh·∫•t ($||X|| = 1$), ta c√≥ th·ªÉ m√£ h√≥a $X$ b·∫±ng $n$ qubits d∆∞·ªõi d·∫°ng:

$$
\ket{\psi_X} = \sum_{i=0}^{N-1}x_i \ket{i},
$$

trong ƒë√≥ $n = \log{N}$. C√≥ th·ªÉ th·∫•y ph∆∞∆°ng ph√°p n√†y ch·ªâ t·ªën $O(\log{N})$ qubits ƒë·ªÉ bi·ªÉu di·ªÖn m·ªôt v√©c-t∆° $N$ chi·ªÅu. H√£y l·∫•y v√≠ d·ª• trong b√†i to√°n x·ª≠ l√Ω ng√¥n ng·ªØ t·ª± nhi√™n, gi·∫£ s·ª≠ b·∫°n c√≥ m·ªôt &lt;em&gt;text corpus&lt;/em&gt; v·ªõi 10000 t·ª´ th√¨ n·∫øu nh∆∞ c√°ch th√¥ng th∆∞·ªùng ta s·ª≠ d·ª•ng &lt;a href=&#34;https://en.wikipedia.org/wiki/One-hot&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;One-hot encoding&lt;/a&gt; ta s·∫Ω c·∫ßn t·ªõi 10000 bits ƒë·ªÉ m√£ h√≥a, nh∆∞ng ƒëi·ªÅu n√†y ho√†n to√°n c√≥ th·ªÉ gi·∫£i quy·∫øt v·ªõi 14 ($\lceil \log{10000} \rceil$) qubits v·ªõi amplitude embedding.&lt;/p&gt;
&lt;p&gt;T·ª´ ƒë√¢y, v·ªõi m·ªói ƒë·∫ßu v√†o $\ket{\psi_{\bf\tilde{x}}}$ m·ªõi, b√†i to√°n s·∫Ω ƒë∆∞·ª£c kh·ªüi t·∫°o d∆∞·ªõi d·∫°ng:&lt;/p&gt;
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/example-1/equation1_hu895413c6cafbee8ea8735175e11f8b65_165324_c12a5c7ac1ed347a463e9f71fb60f756.webp 400w,
               /post/example-1/equation1_hu895413c6cafbee8ea8735175e11f8b65_165324_3f31152c28be40d0d2c5e116e940fd8b.webp 760w,
               /post/example-1/equation1_hu895413c6cafbee8ea8735175e11f8b65_165324_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://example.com/post/example-1/equation1_hu895413c6cafbee8ea8735175e11f8b65_165324_c12a5c7ac1ed347a463e9f71fb60f756.webp&#34;
               width=&#34;760&#34;
               height=&#34;202&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;p&gt;Trong ƒë√≥ $\ket{m}$ v√† $\ket{y^m}$ m√£ h√≥a cho s·ªë th·ª© t·ª± v√† nh√£n t∆∞∆°ng ·ª©ng c·ªßa v√©c-t∆° ƒë·∫ßu v√†o th·ª© $m^{th}$. Tuy nhi√™n ƒëi·ªÅu ch√∫ √Ω ·ªü ƒë√¢y n·∫±m ·ªü &lt;em&gt;ancilla qubit&lt;/em&gt; ƒë∆∞·ª£c k·∫øt n·ªëi v·ªõi $\ket{\psi_{\bf\tilde{{x}}}}$ v√† $\ket{\psi_{\bf{x}^m}}$. Ch√∫ √Ω r·∫±ng khi ta th·ª±c hi·ªán ph√©p do tr√™n m·ªôt ho·∫∑c m·ªôt h·ªá qubits th√¨ qubit(s) s·∫Ω b·ªã &lt;em&gt;collapsed&lt;/em&gt; hay &lt;em&gt;terminated&lt;/em&gt;. V·∫≠y khi ta chuy·ªÉn ph√©p ƒëo c·ªßa $\ket{\psi_{\bf\tilde{{x}}}}$ hay $\ket{\psi_{\bf{x}^m}}$ sang ph√©p ƒëo c·ªßa m·ªôt &lt;em&gt;ancilla qubit&lt;/em&gt; ƒë∆∞·ª£c k·∫øt n·ªëi v·ªõi ch√∫ng th√¨ ta v·∫´n thu ƒë∆∞·ª£c k·∫øt qu·∫£ c·∫ßn thi·∫øt c·ªßa $\ket{\psi_{\bf\tilde{{x}}}}$ v√† $\ket{\psi_{\bf{x}^m}}$ m√† kh√¥ng c·∫ßn ch·∫•m d·ª©t (&lt;em&gt;terminate&lt;/em&gt;) c·∫£ h·ªá th·ªëng. K·ªπ thu·∫≠t n√†y r·∫•t hay s·ª≠ d·ª•ng ·ªü trong c√°c thu·∫≠t to√°n l∆∞·ª£ng t·ª≠ v√† vi·ªác k·∫øt n·ªëi gi·ªØa &lt;em&gt;ancilla qubit&lt;/em&gt; v·ªõi h·ªá th·ªëng l√† ch√∫ng ta ƒëang t·∫°o ra &lt;a href=&#34;https://en.wikipedia.org/wiki/Quantum_entanglement&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;em&gt;entanglement&lt;/em&gt;&lt;/a&gt; - m·ªôt t√≠nh ch·∫•t quan tr·ªçng kh√°c trong lƒ©nh v·ª±c t√≠nh to√°n l∆∞·ª£ng t·ª≠.&lt;/p&gt;
&lt;p&gt;Nh∆∞ v·∫≠y v·ªõi v√≠ d·ª• Titanic tr√™n ta c√≥:
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/example-1/data_processing_hu8c90f3f68a6d31a7f4dad34dc8d04642_53301_06417e8dac8b40de76662264a3b79f5c.webp 400w,
               /post/example-1/data_processing_hu8c90f3f68a6d31a7f4dad34dc8d04642_53301_a62954af2ee2bbe430771a386cb5b63b.webp 760w,
               /post/example-1/data_processing_hu8c90f3f68a6d31a7f4dad34dc8d04642_53301_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://example.com/post/example-1/data_processing_hu8c90f3f68a6d31a7f4dad34dc8d04642_53301_06417e8dac8b40de76662264a3b79f5c.webp&#34;
               width=&#34;760&#34;
               height=&#34;348&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;

$$
\ket{\mathcal{D}} = \frac{1}{\sqrt{4}} \Big\{\ket{0}[\ket{0}(0.866\ket{0}+0.5\ket{1})+\ket{1}(0.921\ket{0}+0.39\ket{1})]\ket{1}
$$
&lt;/p&gt;

$$
+ \ket{1}[\ket{0}(0.866\ket{0}+0.5\ket{1})+\ket{1}(0.141\ket{0}+0.99\ket{1})]\ket{0} \Big\}
$$

&lt;h2 id=&#34;b∆∞·ªõc-2-√°p-d·ª•ng-bi·∫øn-ƒë·ªïi-hadamard&#34;&gt;B∆∞·ªõc 2: √Åp d·ª•ng bi·∫øn ƒë·ªïi Hadamard&lt;/h2&gt;
&lt;p&gt;Nh∆∞ m√¨nh ƒë·ªÅ c·∫≠p t·ªõi b√†i vi·∫øt tr∆∞·ªõc, h·∫ßu h·∫øt c√°c bi·∫øn ƒë·ªïi tr√™n m√°y t√≠nh l∆∞·ª£ng t·ª≠ l√† tuy√™n t√≠nh n√™n vi·ªác th·ª±c hi·ªán c√°c ph√©p bi·∫øn ƒë·ªïi l√† c√°c ph√©p nh√¢n v·ªõi ma tr·∫≠n bi·ªÉu di·ªÖn t∆∞∆°ng ·ª©ng. ·ªû ƒë√¢y, ma tr·∫≠n Hadamard c√≥ d·∫°ng:

$$
H = \frac{1}{\sqrt{2}}\left( \begin{array}{cc} 1 &amp; 1 \\
1 &amp; -1 \end{array} \right)
$$
&lt;/p&gt;
&lt;p&gt;Nh∆∞ v·∫≠y, n·∫øu ta √°p d·ª•ng bi·∫øn ƒë·ªïi Hadamard cho &lt;em&gt;ancilla qubit&lt;/em&gt; ta c√≥:&lt;/p&gt;

$$
\ket{\mathcal{D}} \longrightarrow \frac{1}{\sqrt{2M}} \sum_{m=0}^{M-1} \ket{m}\Big(H\ket{0}\ket{\psi_{\bf\tilde{{x}}}} + H\ket{1}\ket{\psi_{\bf{x}^m}}\Big)\ket{y^m}
$$

&lt;p&gt;V·ªõi nh·ªØng b·∫°n ƒë√£ ƒë·ªçc qua &lt;a href=&#34;https://example.com/post/fair-coins&#34;&gt;B√†i 1&lt;/a&gt; ho·∫∑c v·ªõi m·ªôt ch√∫t t√≠nh to√°n, ch√∫ng ta d·ªÖ d√†ng ch·ª©ng minh ƒë∆∞·ª£c:

$$
H\ket{0} = \frac{1}{\sqrt{2}}(\ket{0}+\ket{1}), H\ket{1} = \frac{1}{\sqrt{2}}(\ket{0}-\ket{1}) 
$$

√Åp d·ª•ng c√¥ng th·ª©c tr√™n, ta ƒë∆∞·ª£c:

$$
\ket{\mathcal{D}}\! \longrightarrow\! \frac{1}{2\sqrt{M}} \sum_{m=0}^{M-1} \ket{m}\Big(\ket{0}(\ket{\psi_{\bf\tilde{{x}}}}+\ket{\psi_{\bf{x}^m}}) + \ket{1}(\ket{\psi_{\bf\tilde{{x}}}}-\ket{\psi_{\bf{x}^m}})\Big)\ket{y^m}
$$
&lt;/p&gt;
&lt;h2 id=&#34;b∆∞·ªõc-3-ph√©p-ƒëo&#34;&gt;B∆∞·ªõc 3: Ph√©p ƒëo&lt;/h2&gt;
&lt;p&gt;·ªû ƒë√¢y ta s·∫Ω c·∫ßn s·ª≠ d·ª•ng l·∫ßn l∆∞·ª£t 2 ph√©p ƒëo tr√™n &lt;em&gt;ancilla qubit&lt;/em&gt; v√† $\ket{y^m}$. Nh∆∞ng tr∆∞·ªõc ƒë√≥ m√¨nh s·∫Ω vi·∫øt l·∫°i k·∫øt qu·∫£ thu ƒë∆∞·ª£c sau b∆∞·ªõc 2:

$$ 
\frac{1}{2\sqrt{M}} \sum_{m=0}^{M-1} \ket{m}\Big(\ket{0}\sum_{i=0}^{N} ({\tilde{{\bf{x}}}}^m_i+{\bf{x}}^m_i)\ket{i} + \ket{1}\sum_{i=0}^{N} ({\tilde{{\bf{x}}}}^m_i-{\bf{x}}^m_i)\ket{i}\Big)\ket{y^m} 
$$
&lt;/p&gt;
&lt;p&gt;&lt;em&gt;1. Ph√©p ƒëo tr√™n ancilla qubit&lt;/em&gt;: ·ªû ph√©p ƒë√≥ n√†y, ta s·∫Ω c√≥ x√°c su·∫•t $p_0 = \Big(\frac{1}{2\sqrt{M}} \sum_{m=0}^{M-1}\sum_{i=0}^{N} ({\tilde{{\bf{x}}}}^m_i+{\bf{x}}^m_i)\Big)^2 = \frac{1}{4M}\sum_M|{\bf\tilde{x}}+{\bf x}^m|^2$ thu ƒë∆∞·ª£c k·∫øt qu·∫£ l√† $0$ v√† t∆∞∆°ng t·ª± ta thu ƒë∆∞·ª£c k·∫øt qu·∫£ 1 t·ª´ &lt;em&gt;ancilla qubit&lt;/em&gt; v·ªõi x√°c su·∫•t $p_1=\frac{1}{4M}\sum_M|{\bf\tilde{x}}-{\bf x}^m|^2$. Tuy nhi√™n ·ªü ƒë√¢y ta s·∫Ω ch·ªâ l·∫•y k·∫øt qu·∫£ thu ƒë∆∞·ª£c n·∫øu &lt;em&gt;ancilla qubit&lt;/em&gt; c√≥ gi√° tr·ªã l√† $0$, hay n√≥i c√°ch kh√°c ta &lt;em&gt;terminate&lt;/em&gt; nh√°nh m√† &lt;em&gt;ancilla qubit&lt;/em&gt; c√≥ tr·∫°ng th√°i l√† $\ket{1}$, ta c√≥:

$$ 
\frac{1}{2\sqrt{Mp_0}} \sum_{m=0}^{M-1} \ket{m}\Big(\ket{0}\sum_{i=0}^{N} ({\tilde{{\bf{x}}}}^m_i+{\bf{x}}^m_i)\ket{i} \Big)\ket{y^m} 
$$
&lt;/p&gt;
&lt;p&gt;Ta nh√¢n $p_0$ ·ªü ƒë√¢y ƒë·ªÉ ch·∫Øc ch·∫Øn r·∫±ng h·ªá th·ªëng c·ªßa ch√∫ng ta v·∫´n l√† ƒë∆°n nh·∫•t (&lt;em&gt;unit length&lt;/em&gt;).&lt;/p&gt;
&lt;p&gt;&lt;em&gt;2. Ph√©p ƒëo tr√™n $\ket{y^m}$&lt;/em&gt;
Ta c√≥ th·ªÉ d·ªÖ d√†ng th·∫•y x√°c su·∫•t thu ƒë∆∞·ª£c c√≥ gi√° tr·ªã b·∫±ng $0$ l√†:

$$ 
p(y=0) = \frac{1}{4Mp_0}\sum_{m|y^m=0}|{\tilde{{\bf{x}}}+{\bf{x}}^m}|^2
$$
&lt;/p&gt;
&lt;p&gt;V√¨ $\tilde{{\bf{x}}}$ hay ${{\bf{x}}}^m$ l√† ƒë∆°n nh·∫•t n√™n ta ho√†n to√†n c√≥ th·ªÉ ch·ª©ng minh ƒë∆∞·ª£c:&lt;/p&gt;

$$ 
\frac{1}{4Mp_0}\sum_{m|y^m=0}|{\tilde{{\bf{x}}}+{\bf{x}}^m}|^2 = 1 - \frac{1}{4Mp_0}\sum_{m|y^m=0}|{\tilde{{\bf{x}}}-{\bf{x}}^m}|^2
$$

&lt;p&gt;B√†i to√°n s·∫Ω ƒë∆∞·ª£c ho√†n to√†n ƒë∆∞a v·ªÅ gi·ªëng v·ªõi k·∫øt qu·∫£ tr∆∞·ªùng h·ª£p tr√™n m√°y t√≠nh truy·ªÅn th·ªëng m√† m√¨nh ƒë·ªÅ c·∫≠p t·ªõi ·ªü tr√™n.&lt;/p&gt;
&lt;p&gt;Ta √°p d·ª•ng b√†i to√°n c·ªßa t·∫≠p Titanic v√†o c√¥ng th·ª©c tr√™n ta ƒë∆∞·ª£c:

$$ 
p(y=0) = \frac{1}{4Mp_0}(|0.141+0.866|^2+|0.990+0.5|^2)  \approx 0.448, 
$$
&lt;/p&gt;

$$ 
p(y=1) = \frac{1}{4Mp_0}(|0.921+0.866|^2+|0.390+0.5|^2)  \approx 0.552, 
$$

&lt;p&gt;Nh∆∞ v·∫≠y c√≥ th·ªÉ th·∫•y k·∫øt qu·∫£ thu ƒë∆∞·ª£c t·ª´ thu·∫≠t to√°n l∆∞·ª£ng t·ª≠ n√†y c≈©ng cho ra k·∫øt qu·∫£ r·∫±ng &lt;em&gt;Passenger 3&lt;/em&gt; s·∫Ω s·ªëng s√≥t.&lt;/p&gt;
&lt;h1 id=&#34;k·∫øt-lu·∫≠n-a-name3a&#34;&gt;K·∫øt lu·∫≠n &lt;a name=&#34;3&#34;&gt;&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;C√≥ th·ªÉ th·∫•y ch√∫ng ta ho√†n to√†n c√≥ th·ªÉ x√¢y d·ª±ng m·ªôt thu·∫≠t to√°n l∆∞·ª£ng t·ª≠ t∆∞∆°ng ƒë∆∞∆°ng trong b√†i to√°n &lt;em&gt;distanced-based classifier&lt;/em&gt;. M·∫∑c d√π v√≠ d·ª• tr√™n ch∆∞a cho ch√∫ng ta th·∫•y ƒë∆∞·ª£c &lt;em&gt;quantum advantage&lt;/em&gt; nh∆∞ng n√≥ gi√∫p m·ªçi ng∆∞·ªùi hi·ªÉu ƒë∆∞·ª£c c·∫•u tr√∫c chung c·ªßa m·ªôt thu·∫≠t to√°n l∆∞·ª£ng t·ª≠ n√≥i chung v√† m√¥ h√¨nh trong QML n√≥i ri√™ng: M√£ h√≥a (embedding) -&amp;gt; C√°c ph√©p bi·∫øn ƒë·ªïi (Transformations) -&amp;gt; Ph√©p ƒëo (Measurement).&lt;/p&gt;
&lt;h1 id=&#34;source-code-a-name4a&#34;&gt;Source Code &lt;a name=&#34;4&#34;&gt;&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;M√£ ngu·ªìn trong b√†i n√†y c√≥ th·ªÉ ƒë∆∞·ª£c t√¨m th·∫•y &lt;a href=&#34;https://github.com/qmlvietnam/CodeforBlog/blob/main/classifier.ipynb&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;t·∫°i ƒë√¢y&lt;/a&gt;.&lt;/p&gt;
&lt;script src=&#34;https://giscus.app/client.js&#34;
        data-repo=&#34;qmlvietnam/qmlvietnam.github.io&#34;
        data-repo-id=&#34;R_kgDOH833kg&#34;
        data-category=&#34;General&#34;
        data-category-id=&#34;DIC_kwDOH833ks4CRwGU&#34;
        data-mapping=&#34;pathname&#34;
        data-strict=&#34;0&#34;
        data-reactions-enabled=&#34;1&#34;
        data-emit-metadata=&#34;0&#34;
        data-input-position=&#34;bottom&#34;
        data-theme=&#34;light_high_contrast&#34;
        data-lang=&#34;vi&#34;
        crossorigin=&#34;anonymous&#34;
        async&gt;
&lt;/script&gt;&lt;blockquote&gt;
&lt;/blockquote&gt;
</description>
    </item>
    
    <item>
      <title>B√†i 1: Quantum vs Classical Interference: First Example</title>
      <link>https://example.com/post/fair-coins/</link>
      <pubDate>Sun, 09 Oct 2022 14:41:26 +0700</pubDate>
      <guid>https://example.com/post/fair-coins/</guid>
      <description>&lt;h2 id=&#34;n·ªôi-dung&#34;&gt;N·ªôi dung&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;#1&#34;&gt;Gi·ªõi thi·ªáu b√†i to√°n&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#2&#34;&gt;Classical Interference&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#3&#34;&gt;Quantum Interference&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#4&#34;&gt;K·∫øt lu·∫≠n&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Tr∆∞·ªõc khi ƒëi v√†o c√°c thu·∫≠t to√°n quantum trong h·ªçc m√°y, m√¨nh mu·ªën so s√°nh b√†i to√°n suy lu·∫≠n x√°c su·∫•t tr√™n m√°y t√≠nh truy·ªÅn th·ªëng c≈©ng nh∆∞ tr√™n m√°y t√≠nh l∆∞·ª£ng t·ª≠. B√†i vi·∫øt n√†y s·∫Ω gi√∫p c√°c b·∫°n vi·∫øt qua nh·ªØng th√†nh ph·∫ßn c∆° b·∫£n c·ªßa v·∫≠t l√Ω l∆∞·ª£ng t·ª≠: &lt;em&gt;&lt;a href=&#34;https://vi.wikipedia.org/wiki/Qubit&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;qubits&lt;/a&gt;&lt;/em&gt;, &lt;em&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Unitary_transformation_%28quantum_mechanics%29&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;unitary transformation&lt;/a&gt;&lt;/em&gt;, v√† &lt;em&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Measurement_in_quantum_mechanics&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;measurement&lt;/a&gt;&lt;/em&gt; v√† c√°ch ho·∫°t ƒë·ªông c·ªßa ch√∫ng th√¥ng qua m·ªôt v√≠ d·ª• c·ª• th·ªÉ.&lt;/p&gt;
&lt;h2 id=&#34;gi·ªõi-thi·ªáu-b√†i-to√°n-a-name1a&#34;&gt;Gi·ªõi thi·ªáu b√†i to√°n &lt;a name=&#34;1&#34;&gt;&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Cho hai ƒë·ªìng xu ƒë·ªìng ch·∫•t: $c_1$ v√† $c_2$ v·ªõi x√°c su·∫•t ·ªü m·∫∑t s·∫•p (&lt;em&gt;tail&lt;/em&gt;) hay m·∫∑t ng·ª≠a (&lt;em&gt;head&lt;/em&gt;) l√† nh∆∞ nhau. Kh√¥ng gian m·∫´u c·ªßa vi·ªác tung 2 ƒë·ªìng xu tr√™n s·∫Ω bao g·ªìm: &lt;em&gt;(head, head)&lt;/em&gt;, &lt;em&gt;(head, tail)&lt;/em&gt;, &lt;em&gt;(tail, head)&lt;/em&gt;, v√† &lt;em&gt;(tail, tail)&lt;/em&gt;. M√¨nh s·∫Ω x√©t b√†i to√°n nh∆∞ sau: B∆∞·ªõc 1, ta l·∫≠t 2 ƒë·ªìng xu th√†nh m·∫∑t ng·ª≠a (&lt;em&gt;head&lt;/em&gt; s·∫Ω l√† gi√° tr·ªã ban ƒë·∫ßu c·ªßa 2 ƒë·ªëng xu). B∆∞·ªõc 2, ta tung ƒë·ªìng xu th·ª© nh·∫•t $c_1$ v√† ki·ªÉm tra k·∫øt qu·∫£. V√† b∆∞·ªõc 3, ta c≈©ng l·∫°i tung ƒë·ªìng xu $c_1$ l·∫ßn th·ª© hai v√† ki·ªÉm tra k·∫øt qu·∫£ (gi·∫£ s·ª≠ k·∫øt qu·∫£ thu ƒë∆∞·ª£c l√† sau s·ªë l·∫ßn th·ª≠ ƒë·ªß l·ªõn).&lt;/p&gt;
&lt;h2 id=&#34;classical-interference-suy-lu·∫≠n-x√°c-su·∫•t-truy·ªÅn-th·ªëng-a-name2a&#34;&gt;Classical Interference (Suy lu·∫≠n x√°c su·∫•t truy·ªÅn th·ªëng) &lt;a name=&#34;2&#34;&gt;&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;C√≥ th·ªÉ th·∫•y v·ªõi m√°y t√≠nh truy·ªÅn th·ªëng (&lt;em&gt;classical computer&lt;/em&gt;), 2 ƒë·ªìng xu c√≥ th·ªÉ ƒë∆∞·ª£c coi l√† 2 bits ng·∫´u nhi√™n (&lt;em&gt;random bits&lt;/em&gt;). ·ªû b∆∞·ªõc 1, b√†i to√°n s·∫Ω ƒë∆∞a v·ªÅ k·∫øt qu·∫£ &lt;em&gt;(head, head)&lt;/em&gt;. Tuy nhi√™n, sau b∆∞·ªõc hai th√¨ &lt;em&gt;(head, head)&lt;/em&gt; v√† &lt;em&gt;(tail, head)&lt;/em&gt; s·∫Ω c√≥ x√°c su·∫•t b·∫±ng nhau v√† b·∫±ng 0.5. Ph√¢n ph·ªëi n√†y s·∫Ω kh√¥ng thay ƒë·ªïi sau b∆∞·ªõc 3.&lt;/p&gt;
&lt;h2 id=&#34;quantum-interference-suy-lu·∫≠n-x√°c-su·∫•t-tr√™n-m√°y-t√≠nh-quantum-a-name3a&#34;&gt;Quantum Interference (Suy lu·∫≠n x√°c su·∫•t tr√™n m√°y t√≠nh quantum) &lt;a name=&#34;3&#34;&gt;&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Tuy nhi√™n, ·ªü ƒë√¢y s·∫Ω c√≥ m·ªôt ch√∫t kh√°c bi·ªát n·∫øu ta bi·ªÉu di·ªÖn b√†i to√°n tr√™n m√°y t√≠nh quantum. Hai ƒë·ªìng xu s·∫Ω ƒë∆∞·ª£c bi·ªÉu di·ªÖn b·∫±ng hai &lt;em&gt;&lt;a href=&#34;https://vi.wikipedia.org/wiki/Qubit&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;qubits&lt;/a&gt;&lt;/em&gt; (quantum bits). M·ªói qubit c√≥ d·∫°ng $\alpha \ket{0} + \beta \ket{1}$, trong ƒë√≥ $\ket{0}$ v√† $\ket{1}$ l√† hai tr·∫°ng th√°i c∆° s·ªü (&lt;em&gt;basis state&lt;/em&gt;) ƒë∆∞·ª£c bi·ªÉu di·ªÖn d∆∞·ªõi d·∫°ng v√©c-t∆° t∆∞∆°ng ·ª©ng: $[1,0]^T$ v√† $[0,1]^T$. C√≥ th·ªÉ th·∫•y r·∫±ng $\ket{0}$ v√† $\ket{1}$ t∆∞∆°ng ·ª©ng v·ªõi hai gi√° tr·ªã nh·ªã ph√¢n 0, 1 ·ªü m√°y t√≠nh truy·ªÅn th·ªëng; tuy nhi√™n, thay v√¨ ƒë∆∞·ª£c m√£ h√≥a r·ªùi r·∫°c th√†nh chu·ªói bit 1 ho·∫∑c 0, m·ªói &lt;em&gt;qubit&lt;/em&gt; c√≥ th·ªÉ t·∫°o th√†nh m·ªôt t·ªï h·ª£p tuy·∫øn t√≠nh c·ªßa c√°c tr·∫°ng th√°i c∆° s·ªü theo x√°c su·∫•t:

$$
p(0) = |\alpha|^2, p(1) = |\beta|^2; \alpha, \beta \in \mathbb{C}
$$
 &lt;br&gt;
Ch√∫ √Ω r·∫±ng $|\alpha|^2 + |\beta|^2 = 1$ ƒë·ªÉ th·ªèa m√£n x√°c su·∫•t tr√™n. Nh∆∞ v·∫≠y n·∫øu ta coi hai m·∫∑t c·ªßa ƒë·ªìng xu l√† hai tr·∫°ng th√°i c∆° s·ªü: $\ket{head} = \ket{0}$ v√† $\ket{tail} = \ket{1}$, th√¨ vi·ªác tung ƒë·ªìng xu s·∫Ω t∆∞∆°ng ƒë∆∞∆°ng vi·ªác ch√∫ng ta th·ª±c hi·ªán bi·∫øn ƒë·ªïi &lt;a href=&#34;https://en.wikipedia.org/wiki/Hadamard_transform&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Hadamard&lt;/a&gt;. Vi·ªác bi·∫øn ƒë·ªïi ·ªü ƒë√¢y tr√™n m√°y t√≠nh quantum ch√≠nh l√† ph√©p nh√¢n ma tr·∫≠n Hadamard v·ªõi tr·∫°ng th√°i hi·ªán t·∫°i c·ªßa qubit. Trong ƒë√≥ bi·∫øn ƒë·ªïi Hadamard c√≥ th·ªÉ ƒë∆∞·ª£c bi·ªÉu di·ªÖn d∆∞·ªõi d·∫°ng ma tr·∫≠n:&lt;/p&gt;

$$
H = \frac{1}{\sqrt{2}}\left( \begin{array}{cc} 1 &amp; 1 \\
1 &amp; -1 \end{array} \right)
$$

&lt;p&gt;T·ª´ ƒë√≥, ta c√≥ th·ªÉ tri·ªÉn khai b√†i to√°n tr√™n nh∆∞ sau: 2 qubits s·∫Ω ƒë∆∞·ª£c kh·ªüi t·∫°o th√†nh $\ket{head}\ket{head}$ sau b∆∞·ªõc 1. ·ªû b∆∞·ªõc 2, ta nh√¢n ma tr·∫≠n Hadamard v·ªõi tr·∫°ng th√°i c·ªßa qubit th·ª© nh·∫•t, ta c√≥:

$$
  H\ket{head}\ket{head}= H\ket{0}\ket{head} = \frac{1}{\sqrt{2}}\left( \begin{array}{cc} 1 &amp; 1 \\
1 &amp; -1 \end{array} \right) \left( \begin{array}{c} 1 \\ 0 \end{array} \right) \ket{head}   
$$


$$
=\!\frac{1}{\sqrt{2}}\left( \begin{array}{c} 1 \\ 1 \end{array} \right)\! \ket{head}\! =\! \frac{1}{\sqrt{2}} (\ket{0}\!+\!\ket{1})\!\ket{head}\! =\! \frac{1}{\sqrt{2}} (\ket{head}\!+\!\ket{tail})\!\ket{head}
$$


$$
= \frac{1}{\sqrt{2}}\ket{head}\ket{head} + \frac{1}{\sqrt{2}}\ket{tail}\ket{head}   
$$

Nh∆∞ v·∫≠y, ta th·∫•y gi·ªëng nh∆∞ tr∆∞·ªùng h·ª£p tr√™n, sau b∆∞·ªõc 2 x√°c su·∫•t ƒë·∫°t ƒë∆∞·ª£c $\ket{head}\ket{head}$ v√† $\ket{tail}\ket{head}$ l√† b·∫±ng nhau l√† c≈©ng b·∫±ng $(\frac{1}{\sqrt{2}})^2 = 0.5$. Tuy nhi√™n s·ª± kh√°c bi·ªát n·∫±m ·ªü b∆∞·ªõc 3, n·∫øu ta ti·∫øp t·ª•c tung ƒë·ªìng xu th·ª© nh·∫•t (hay th·ª±c hi·ªán bi·∫øn ƒë·ªïi Hadamard), v·ªõi m·ªôt ch√∫t t√≠nh to√°n ta nh·∫≠n ƒë∆∞·ª£c k·∫øt qu·∫£:&lt;/p&gt;
&lt;p&gt;
$$
\frac{1}{\sqrt{2}}H\ket{head}\ket{head} + \frac{1}{\sqrt{2}}H\ket{tail}\ket{head} = \ket{head}\ket{head}   
$$

Sau b∆∞·ªõc 3 ta s·∫Ω lu√¥n nh·∫≠n ƒë∆∞·ª£c $\ket{head}\ket{head}$, k·∫øt qu·∫£ n√†y kh√°c ho√†n to√°n khi th·ª±c hi·ªán b√†i to√°n tr√™n m√°y t√≠nh truy·ªÅn th·ªëng. C√≥ th·ªÉ n√≥i ƒë√¢y l√† m·ªôt s·ª± kh√°c nhau th√∫ v·ªã gi·ªØa m√°y t√≠nh l∆∞·ª£ng t·ª≠ v√† m√°y t√≠nh truy·ªÅn th·ªëng. Kh√°c v·ªõi m√°y t√≠nh truy·ªÅn th·ªëng c√≥ xu h∆∞·ªõng t·ªëi ƒëa h√≥a s·ª± kh√¥ng ch·∫Øc ch·∫Øn (&lt;em&gt;maximize uncertainty&lt;/em&gt;) v√¨ lu√¥n cho ra k·∫øt qu·∫£ 50-50 gi·ªØa 2 tr·∫°ng th√°i (head, head) v√† (tail, head), th√¨ m√°y t√≠nh l∆∞·ª£ng t·ª≠ cho ra k·∫øt qu·∫£ c√≥ ƒë·ªô kh√¥ng ch·∫Øc ch·∫Øn th·∫•p h∆°n. Ch√≠nh v√¨ l√Ω do n√†y, ƒë√£ c√≥ nghi√™n c·ª©u √°p d·ª•ng &lt;em&gt;quantum inference&lt;/em&gt; nh∆∞ m·ªôt h√†m d·ª± ƒëo√°n (prediction function) trong b√†i to√°n h·ªçc m√°y c√≥ gi√°m s√°t (supervised learning) [&lt;a href=&#34;https://arxiv.org/abs/2004.01227&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;1&lt;/a&gt;]&lt;/p&gt;
&lt;p&gt;S·ª± kh√°c nhau tr√™n c≈©ng d·∫´n ta t·ªõi m·ªôt v·∫•n ƒë·ªÅ quan tr·ªçng kh√°c: &lt;em&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Measurement_in_quantum_mechanics&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;measurement&lt;/a&gt;&lt;/em&gt; (ph√©p ƒëo). Ph√©p ƒëo ch√≠nh l√† c·∫ßu n·ªëi gi·ªØa &lt;em&gt;quantum&lt;/em&gt; v√† &lt;em&gt;classical&lt;/em&gt;, gi√∫p ch√∫ng ta ƒë√°nh gi√° v√† ph√¢n t√≠ch tr·∫°ng th√°i hi·ªán t·∫°i c·ªßa m·ªôt ho·∫∑c m·ªôt h·ªá qubit, v√† n√≥ th∆∞·ªùng mang t√≠nh th·ªëng k√™ x√°c su·∫•t h∆°n l√† m·ªôt ƒë√°nh gi√° ƒë∆°n l·∫ª. N√≥i c√°ch kh√°c, ph√©p ƒëo cho ph√©p ch√∫ng ta ph√° b·ªè t√≠nh ch·ªëng ch√¢t c·ªßa qubits (ph√° b·ªè ƒëi t·ªï h·ª£p tuy·∫øn t√≠nh), t·ª´ ƒë√≥ l√†m cho tr·∫°ng th√°i c·ªßa qubit &lt;em&gt;&amp;lsquo;collapse&amp;rsquo;&lt;/em&gt; v·ªÅ m·ªôt trong c√°c tr·∫°ng th√°i c∆° s·ªü. V√≠ d·ª•, th·ª±c hi·ªán ph√©p ƒëo m·ªôt qubit b·∫•t k·ª≥ $\ket{\phi} = \alpha \ket{0} + \beta \ket{1}$ tr√™n c∆° s·ªü chu·∫©n (&lt;em&gt;canonical basis&lt;/em&gt;) th√¨ ta s·∫Ω ƒë·∫°t ƒë∆∞·ª£c gi√° tr·ªã 0 v·ªõi x√°c su·∫•t l√† $|\alpha|^2$ v√† gi√° tr·ªã 1 v·ªõi x√°c su·∫•t $|\beta|^2$. K·∫øt qu·∫£ thu ƒë∆∞·ª£c t·ª´ ph√©p ƒëo s·∫Ω l√† m·ªôt th·ªëng k√™ x√°c su·∫•t.&lt;/p&gt;
&lt;p&gt;Gi·ªù m√¨nh s·∫Ω tri·ªÉn khai l·∫°i b√†i to√°n tr√™n n·∫øu ta th·ª±c hi·ªán ph√©p ƒëo gi·ªØa b∆∞·ªõc 2 v√† b∆∞·ªõc 3. Sau b∆∞·ªõc 2, tr·∫°ng th√°i c·ªßa 2 ƒë·ªìng xu c√≥ d·∫°ng: $\frac{1}{\sqrt{2}}\ket{head}\ket{head} + \frac{1}{\sqrt{2}}\ket{tail}\ket{head}$. N·∫øu ta th·ª±c hi·ªán ph√©p ƒëo ·ªü ƒë√¢y, ta c√≥ 50% thu ƒë∆∞·ª£c $\ket{head}\ket{head}$ v√† 50% thu ƒë∆∞·ª£c $\ket{tail}\ket{head}$. Do ƒë√≥ ·ªü b∆∞·ªõc 3 ta x√©t hai tr∆∞·ªùng h·ª£p:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Tr∆∞·ªùng h·ª£p I:

$$
H\ket{head}\ket{head} = \frac{1}{\sqrt{2}}\ket{head}\ket{head} + \frac{1}{\sqrt{2}}\ket{tail}\ket{head}   
$$
&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Tr∆∞·ªùng h·ª£p II:

$$
H\ket{tail}\ket{head} = \frac{1}{\sqrt{2}}\ket{head}\ket{head} - \frac{1}{\sqrt{2}}\ket{tail}\ket{head}   
$$
&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;C√≥ th·ªÉ th·∫•y ·ªü hai tr∆∞·ªùng h·ª£p th√¨ sau b∆∞·ªõc 3 ƒë·ªÅu cho ra tr·∫°ng th√°i $\ket{head}\ket{head}$ hay $\ket{tail}\ket{head}$ v·ªõi x√°c su·∫•t $(\pm\frac{1}{\sqrt{2}})^2 = 0.5$ v√† s·∫Ω gi·ªëng v·ªõi k·∫øt qu·∫£ c·ªßa m√°y t√≠nh truy·ªÅn th·ªëng.&lt;/p&gt;
&lt;h2 id=&#34;k·∫øt-lu·∫≠n-a-name4a&#34;&gt;K·∫øt lu·∫≠n &lt;a name=&#34;4&#34;&gt;&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Tr√™n ƒë√¢y, m√¨nh ƒë√£ ƒë∆∞a ra v√≠ d·ª• so s√°nh kh·∫£ nƒÉng suy lu·∫≠n x√°c su·∫•t c·ªßa m√°y t√≠nh truy·ªÅn th·ªëng v√† m√°y t√≠nh l∆∞·ª£ng t·ª≠. Ngo√†i ra m√¨nh gi·ªõi thi·ªáu s∆° b·ªô v·ªÅ th√†nh ph·∫ßn c∆° b·∫£n trong v·∫≠t l√Ω l∆∞·ª£ng t·ª≠ nh∆∞ qubits, c√°ch tri·ªÉn khai ph√©p bi·∫øn ƒë·ªïi, v√† ph√©p ƒëo.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Kh√°c v·ªõi m√°y t√≠nh truy·ªÅn th·ªëng c√≥ xu h∆∞·ªõng t·ªëi ƒëa h√≥a s·ª± kh√¥ng ch·∫Øc ch·∫Øn, th√¨ m√°y t√≠nh l∆∞·ª£ng t·ª≠ cho ra k·∫øt qu·∫£ c√≥ ƒë·ªô kh√¥ng ch·∫Øc ch·∫Øn th·∫•p h∆°n.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Qubit c√≥ d·∫°ng t·ªï h·ª£p tuy·∫øn t√≠nh c·ªßa c√°c tr·∫°ng th√°i c∆° s·ªü d·ª±a theo m·ªôt x√°c su·∫•t.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Trong m√°y t√≠nh l∆∞·ª£ng t·ª≠, ph√©p bi·∫øn ƒë·ªïi l√† ph√©p nh√¢n ma tr·∫≠n t∆∞∆°ng ·ª©ng v·ªõi tr·∫°ng th√°i hi·ªán t·∫°i c·ªßa qubit.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Ph√©p ƒëo l√† c·∫ßu n·ªëi gi·ªØa &lt;em&gt;&amp;lsquo;quantum&amp;rsquo;&lt;/em&gt; v√† &lt;em&gt;&amp;lsquo;classical&amp;rsquo;&lt;/em&gt; ph√° b·ªè ƒëi t√≠nh ch·ªìng ch·∫•t c·ªßa m·ªôt ho·∫∑c m·ªôt h·ªá qubits v√† cho ra k·∫øt qu·∫£ l√† m·ªôt th·ªëng k√™ x√°c su·∫•t.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;C·∫£m ∆°n m·ªçi ng∆∞·ªùi ƒë√£ ƒë·ªçc b√†i.&lt;/p&gt;
&lt;script src=&#34;https://giscus.app/client.js&#34;
        data-repo=&#34;qmlvietnam/qmlvietnam.github.io&#34;
        data-repo-id=&#34;R_kgDOH833kg&#34;
        data-category=&#34;General&#34;
        data-category-id=&#34;DIC_kwDOH833ks4CRwGU&#34;
        data-mapping=&#34;pathname&#34;
        data-strict=&#34;0&#34;
        data-reactions-enabled=&#34;1&#34;
        data-emit-metadata=&#34;0&#34;
        data-input-position=&#34;bottom&#34;
        data-theme=&#34;light_high_contrast&#34;
        data-lang=&#34;vi&#34;
        crossorigin=&#34;anonymous&#34;
        async&gt;
&lt;/script&gt;&lt;blockquote&gt;
&lt;/blockquote&gt;
</description>
    </item>
    
    <item>
      <title>B√†i 0: Gi·ªõi thi·ªáu v·ªÅ Quantum Machine Learning</title>
      <link>https://example.com/post/why-qml/</link>
      <pubDate>Fri, 30 Sep 2022 22:37:50 +0700</pubDate>
      <guid>https://example.com/post/why-qml/</guid>
      <description>&lt;h2 id=&#34;n·ªôi-dung&#34;&gt;N·ªôi dung&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;#1&#34;&gt;Quantum Machine Learning l√† g√¨?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#2&#34;&gt;M·ªôt v√†i h∆∞·ªõng ti·∫øp c·∫≠n c·ªßa Quantum Machine Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#3&#34;&gt;K·∫øt lu·∫≠n&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Kh√°c v·ªõi c√°c ch·ªß ƒë·ªÅ c·ªßa Machine Learning hay Deep Learning khi m√† c√°c ·ª©ng d·ª•ng c·ªßa ch√∫ng ƒëang d·∫ßn tr·ªü n√™n ph·ªï bi·∫øn nh·ªØng nƒÉm g·∫ßn ƒë√¢y, ch·ªß ƒë·ªÅ v·ªÅ Quantum Machine Learning (hay QML) l√† m·ªôt lƒ©nh v·ª±c nghi√™n c·ª©u m·ªõi v√† ƒëang ƒë∆∞·ª£c ch√∫ √Ω ·ªü c√°c c√¥ng ty h√†ng ƒë·∫ßu th·∫ø gi·ªõi nh∆∞ &lt;a href=&#34;https://quantum-computing.ibm.com/lab/docs/iql/machine-learning&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;IBM&lt;/a&gt; hay &lt;a href=&#34;https://quantumai.google/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Google&lt;/a&gt;. Do ƒë√≥, ·ªü b√†i vi·∫øt n√†y ngo√†i vi·ªác cung c·∫•p cho b·∫°n ƒë·ªçc c√°i nh√¨n c·ª• th·ªÉ Quantum Machine Learning l√† g√¨, m√¨nh c≈©ng s·∫Ω gi·∫£i th√≠ch t·∫°i sao ch√∫ng ta l·∫°i c·∫ßn QML v√† m·ªôt v√†i h∆∞·ªõng ti·∫øp c·∫≠n c·ª• th·ªÉ.&lt;/p&gt;
&lt;h2 id=&#34;quantum-machine-learning-l√†-g√¨-a-name1a&#34;&gt;Quantum Machine Learning l√† g√¨? &lt;a name=&#34;1&#34;&gt;&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;N·∫øu nh∆∞ ai ƒë√£ l√†m quen v·ªõi c√°c b√†i to√°n c·ªßa Machine Learning hay Deep Learning, c√°c m√¥ h√¨nh ƒëang d·∫ßn ƒë∆∞·ª£c x√¢y d·ª±ng l·ªõn h∆°n v√† ph·ª©c t·∫°p h∆°n ƒë·ªÉ gi·∫£i quy·∫øt c√°c b√†i to√°n kh√≥ (hard combinatorial optimization problems), n√≥ d·∫´n t·ªõi vi·ªác ti√™u t·ªën r·∫•t nhi·ªÅu t√†i nguy√™n t√≠nh to√°n (computational resources) trong vi·ªác hu·∫•n luy·ªán c≈©ng nh∆∞ l√† v·∫≠n h√†nh. M·ªôt v√≠ d·ª• ƒëi·ªÉn h√¨nh l√† m√¥ h√¨nh &lt;a href=&#34;https://lambdalabs.com/blog/demystifying-gpt-3/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GPT-3&lt;/a&gt; g·ªìm 175 t·ª∑ tham s·ªë s·∫Ω c·∫ßn t·ªën 355 nƒÉm v√† g·∫ßn 5 tri·ªáu ƒë√¥ n·∫øu train tr√™n m·ªôt NVIDIA Tesla V100 GPU. Do ƒë√≥, tr√™n th·ª±c t·∫ø h·ªç ƒë√£ train GPT-3 v·ªõi 1024 A100 GPUs v√† m·∫•t 34 ng√†y.&lt;/p&gt;
&lt;p&gt;Tuy nhi√™n, v·∫•n ƒë·ªÅ ƒë√≥ c√≥ th·ªÉ s·∫Ω ƒë∆∞·ª£c gi·∫£i quy·∫øt v·ªõi s·ª± xu·∫•t hi·ªán c·ªßa m√°y t√≠nh l∆∞·ª£ng t·ª≠ (quantum computer). M√°y t√≠nh l∆∞·ª£ng t·ª≠ ƒë∆∞·ª£c ph√°t tri·ªÉn d·ª±a theo c√°c thuy·∫øt c·ªßa v·∫≠t l√Ω l∆∞·ª£ng t·ª≠ ƒë·ªÉ ƒë∆∞a ra m·ªôt kh·∫£ nƒÉng t√≠nh to√°n v∆∞·ª£t tr·ªôi so v·ªõi m√°y t√≠nh truy·ªÅn th·ªëng. H√£y l·∫•y m·ªôt b√†i to√°n t√¨m ki·∫øm l√† m·ªôt v√≠ d·ª•: gi·∫£ s·ª≠ b·∫°n ph·∫£i t√¨m 1 qu·∫£ b√≥ng trong 1 tri·ªáu ngƒÉn k√©o v√† c√¢u h·ªèi l√† b·∫°n s·∫Ω ph·∫£i m·ªü qua bao nhi√™u ngƒÉn k√©o tr∆∞·ªõc khi t√¨m ƒë∆∞·ª£c qu·∫£ b√≥ng ƒë√≥? ƒê√¥i khi b·∫°n s·∫Ω may m·∫Øn t√¨m ƒë∆∞·ª£c qu·∫£ b√≥ng trong ch·ªâ v√†i l·∫ßn th·ª≠ v√† ng∆∞·ª£c l·∫°i b·∫°n c≈©ng c√≥ th·ªÉ ph·∫£i m·ªü g·∫ßn nh∆∞ to√†n b·ªô 1 tri·ªáu ngƒÉn k√©o kia. Trung b√¨nh b·∫°n s·∫Ω c·∫ßn t·ªõi 500,000 l∆∞·ª£t ƒë·ªÉ t√¨m ra qu·∫£ b√≥ng. Tuy nhi√™n, v·ªõi m√°y t√≠nh l∆∞·ª£ng t·ª≠, b·∫°n c√≥ th·ªÉ th·ª±c hi·ªán b√†i to√°n ƒë√≥ trong v√≤ng 1000 l∆∞·ª£t b·∫±ng m·ªôt thu·∫≠t to√°n ƒë∆∞·ª£c g·ªçi l√† &lt;a href=&#34;https://en.wikipedia.org/wiki/Grover%27s_algorithm&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Grover&amp;rsquo;s algorithm&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;T·ª´ ƒë√≥ s·ª± ra ƒë·ªùi c·ªßa Quantum Machine Learning nh∆∞ m·ªôt s·ª± giao thoa c·ªßa c√°c thu·∫≠t to√°n tr√™n m√°y t√≠nh l∆∞·ª£ng t·ª≠ v·ªõi m√¥ h√¨nh Machine Learning ƒë·ªÉ c·∫£i thi·ªán c·∫£ v·ªÅ m·∫∑t t√≠nh to√°n c≈©ng nh∆∞ ƒë·ªô ch√≠nh x√°c (ƒë∆∞·ª£c g·ªçi l√† &lt;a href=&#34;https://en.wikipedia.org/wiki/Quantum_supremacy&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;quantum advantage&lt;/a&gt;).&lt;/p&gt;
&lt;h2 id=&#34;m·ªôt-v√†i-h∆∞·ªõng-ti·∫øp-c·∫≠n-c·ªßa-quantum-machine-learning-a-name2a&#34;&gt;M·ªôt v√†i h∆∞·ªõng ti·∫øp c·∫≠n c·ªßa Quantum Machine Learning &lt;a name=&#34;2&#34;&gt;&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Cho ƒë·∫øn n√†y ƒë√£ c√≥ kh√° nhi·ªÅu h∆∞·ªõng tri·ªÉn khai QML ƒë∆∞·ª£c ƒë·ªÅ xu·∫•t, m·∫∑c d√π nhi·ªÅu trong s·ªë ch√∫ng v·∫´n ch·ªâ l√† l√Ω thuy·∫øt thu·∫ßn t√∫y v√† c·∫ßn m·ªôt m√°y t√≠nh l∆∞·ª£ng t·ª≠ ho√†n ch·ªânh ƒë·ªÉ th·ª±c nghi·ªám; tuy nhi√™n, c≈©ng ƒë√£ c√≥ c√°c thu·∫≠t to√°n ƒë√£ ƒë∆∞·ª£c tri·ªÉn khai tr√™n quy m√¥ nh·ªè v√† ch·ª©ng minh ƒë·∫°t ƒë∆∞·ª£c &amp;lsquo;quantum advantage&amp;rsquo;. Sau ƒë√¢y m√¨nh s·∫Ω ƒë·ªÅ c·∫≠p t·ªõi hai h∆∞·ªõng ti·ªáp c·∫≠n ph·ªï bi·∫øn c·ªßa QML.&lt;/p&gt;
&lt;p&gt;a) QRAM-based Quantum Machine Learning&lt;/p&gt;
&lt;p&gt;T∆∞∆°ng t·ª± RAM (Random Access Memory) ·ªü c√°c m√°y t√≠nh truy·ªÅn th·ªëng, c√°c nh√† nghi√™n c·ª©u ƒë√£ gi·ªõi thi·ªáu m·ªôt &amp;lsquo;quantum-version&amp;rsquo; c·ªßa RAM ƒë∆∞·ª£c g·ªçi l√† &lt;a href=&#34;https://en.wikipedia.org/wiki/Quantum_memory&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;QRAM&lt;/a&gt; ƒë·ªÉ x·ª≠ l√Ω v·∫•n ƒë·ªÅ ghi v√† ƒë·ªçc th√¥ng tin tr√™n m√°y t√≠nh l∆∞·ª£ng t·ª≠. C√≥ th·ªÉ n√≥i QRAM l√† m·ªôt ph·∫ßn r·∫•t quan tr·ªçng nhi·ªÅu thu·∫≠t to√°n c·ªßa QML. Th·∫≠m ch√≠ ch√∫ng ƒë·∫°t ƒë∆∞·ª£c &amp;lsquo;quantum advantage&amp;rsquo; l√† nh·ªù QRAM.&lt;/p&gt;
&lt;p&gt;M·ªôt ·ª©ng d·ª•ng c·ª• th·ªÉ v√† c≈©ng nh∆∞ ƒë∆∞·ª£c d√πng nhi·ªÅu nh·∫•t c·ªßa QRAM l√† kh·∫£ nƒÉng c·∫£i thi·ªán t·ªëc ƒë·ªô t√≠nh to√°n c·ªßa t√≠ch v√¥ h∆∞·ªõng (dot product) hay &lt;a href=&#34;https://en.wikipedia.org/wiki/Kernel_method&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Kernel Method&lt;/a&gt; - m·ªôt ph∆∞∆°ng ph√°p quen thu·ªôc c·ªßa Machine Learning m√† ƒëi·ªÉn h√¨nh l√† Support Vector Machine (SVM). V·ªõi s·ª± can thi·ªáp c·ªßa QRAM, ta c√≥ th·ªÉ t√≠nh t√≠ch v√¥ h∆∞·ªõng $x^Ty$ v·ªõi ƒë·ªô ph·ª©c t·∫°p l√† $O(logN)$ so v·ªõi $O(N)$ tr√™n m√°y t√≠nh truy·ªÅn th·ªëng, trong ƒë√≥ $x, y$ l√† c√°c vectors $N$ chi·ªÅu.&lt;/p&gt;
&lt;p&gt;T·ª´ ƒë√≥ c√°c thu·∫≠t to√°n ƒë∆∞·ª£c ra ƒë·ªùi nh∆∞ l√† &lt;a href=&#34;https://arxiv.org/abs/1401.2142&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Quantum K-Means&lt;/a&gt; d·ª±a v√†o QRAM ƒë·ªÉ c√≥ ƒë·ªô ph·ª©c t·∫°p $O(log(Nd))$ (so v·ªõi $O(Nd)$ c·ªßa thu·∫≠t to√°n K-Means), trong ƒë√≥ $N$ l√† s·ªë data v√† $d$ l√† s·ªë chi·ªÅu. Hay &lt;a href=&#34;https://arxiv.org/abs/1307.0471&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Quantum Support Vector Machine&lt;/a&gt; ƒë·∫°t ƒë∆∞·ª£c ƒë·ªô ph·ª©c t·∫°p $O(log(Nd))$ so v·ªõi $O(poly(N,d))$ c·ªßa thu·∫≠t to√°n SVM b√¨nh th∆∞·ªùng, v√† m·ªôt s·ªë kh√°c: &lt;a href=&#34;https://arxiv.org/abs/1307.0401&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Quantum PCA&lt;/a&gt;, &lt;a href=&#34;https://link.springer.com/article/10.1007/s10994-012-5316-5&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Quantum K-Medians&lt;/a&gt;, etc.&lt;/p&gt;
&lt;p&gt;·ªû h∆∞·ªõng ti·∫øp c·∫≠n n√†y, c√°c thu·∫≠t to√°n s·∫Ω d·ª±a v√†o kh·∫£ nƒÉng t√≠nh to√°n v∆∞·ª£t tr·ªôi c·ªßa quantum computing ƒë·ªÉ c·∫£i thi·ªán ƒë·ªô ph·ª©c t·∫°p. Tuy nhi√™n ·ªü m√°y t√≠nh l∆∞·ª£ng t·ª≠ kh√¥ng ch·ªâ c√≥ v·∫≠y. Th√¥ng tin ·ªü ƒë√≥ ƒë∆∞·ª£c bi·ªÉu di·ªÖn d·ª±a theo nguy√™n l√Ω ch·ªìng ch·∫≠p (&lt;a href=&#34;https://en.wikipedia.org/wiki/Quantum_superposition&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Superposition&lt;/a&gt;), thay v√¨ ƒë∆∞·ª£c m√£ h√≥a r·ªùi r·∫°c th√†nh c√°c bits 0 v√† 1, c√≥ nghƒ©a th√¥ng tin c√≥ th·ªÉ t·ªìn t·∫°i ƒë·ªìng th·ªùi ·ªü bit 0 v√† bit 1 theo m·ªôt ph√¢n ph·ªëi n√†o ƒë√≥. Do ƒë√≥, &amp;rsquo;learning space&amp;rsquo; ·ªü m√°y t√≠nh l∆∞·ª£ng t·ª≠ s·∫Ω ho√†n to√†n kh√°c v√† th·∫≠m ch√≠ ƒë∆∞·ª£c m·ªü r·ªông h∆°n so v·ªõi m√°y t√≠nh truy·ªÅn th·ªëng. Th·ª±c t·∫ø ƒë√£ c√≥ nhi·ªÅu nghi√™n c·ª©u v·ªõi m·ª•c ti√™u kh√°m ph√° kh√¥ng gian n√†y ƒë·ªÉ c·∫£i thi·ªán kh·∫£ nƒÉng h·ªçc t·∫≠p (learning capability) c·ªßa m√¥ h√¨nh Machine Learning v√† h∆∞·ªõng ti·∫øp c·∫≠n sau ƒë√¢y l√† v√≠ d·ª• ƒëi·ªÉn h√¨nh cho vi·ªác n√†y.&lt;/p&gt;
&lt;p&gt;b) Quantum Neural Network.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.google.com/url?sa=i&amp;amp;url=https%3A%2F%2Fwww.researchgate.net%2Ffigure%2FComparison-between-a-classical-neural-networks-and-b-quantum-neural-networks-used-for_fig3_345261288&amp;amp;psig=AOvVaw0GZmtR456ENI7xPiIde2Qb&amp;amp;ust=1664949826824000&amp;amp;source=images&amp;amp;cd=vfe&amp;amp;ved=0CAwQjRxqFwoTCKCo69PzxfoCFQAAAAAdAAAAABAN&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://www.researchgate.net/profile/Zhenyu-Cai-3/publication/345261288/figure/fig3/AS:953988396642305@1604459966798/Comparison-between-a-classical-neural-networks-and-b-quantum-neural-networks-used-for.ppm&#34; alt=&#34;Source&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;ƒê∆∞·ª£c th√∫c ƒë·∫©y t·ª´ s·ª± th√†nh c√¥ng c·ªßa m·∫°ng h·ªçc s√¢u (classical deep learning), m·∫°ng n∆°-ron l∆∞·ª£ng t·ª≠ (&lt;a href=&#34;https://en.wikipedia.org/wiki/Quantum_neural_network&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Quantum Neural Network&lt;/a&gt;, hay QNN) c≈©ng mang nh·ªØng n√©t t∆∞∆°ng ƒë·ªìng v·ªõi m·∫°ng n∆°-ron truy·ªÅn th·ªëng (NN). Ch√∫ng ƒë∆∞·ª£c thi·∫øt k·∫ø theo c·∫•u tr√∫c &lt;a href=&#34;https://en.wikipedia.org/wiki/Feedforward_neural_network&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;feed-forward&lt;/a&gt;, trong ƒë√≥ c√°c layers l√† c√°c ph√©p bi·∫øn ƒë·ªïi ƒë∆°n nh·∫•t (&lt;a href=&#34;https://en.wikipedia.org/wiki/Unitary_transformation#:~:text=In%20mathematics%2C%20a%20unitary%20transformation,inner%20product%20after%20the%20transformation.&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;unitary transformation&lt;/a&gt;). H·∫ßu h·∫øt c·∫•u tr√∫c c·ªßa QNN d·ª±a theo &lt;a href=&#34;https://pennylane.ai/qml/glossary/variational_circuit.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Variational Quantum Circuits&lt;/a&gt; hay th∆∞·ªùng ƒë∆∞·ª£c g·ªçi Parameterised Quantum Circuits. ·ªû ƒë√≥ c√°c bi·∫øn ƒë·ªïi trong c·∫•u tr√∫c m·∫°ng QNN s·∫Ω ph·ª• thu·ªôc v√†o tham s·ªë $\theta$ (learning parameters) v√† ch√∫ng s·∫Ω thay ƒë·ªïi trong qu√° tr√¨nh t·ªëi ∆∞u.&lt;/p&gt;
&lt;p&gt;ƒê·∫øn nay, ƒë√£ c√≥ kh√° nhi·ªÅu nghi√™n c·ª©u b·∫Øt ƒë·∫ßu nh·ªØng b∆∞·ªõc s∆° khai trong vi·ªác ·ª©ng d·ª•ng QNN v√†o c√°c b√†i to√°n m√† t·∫°o n√™n th√†nh c√¥ng c·ªßa Deep Learning (image classification, natural language processing): &lt;a href=&#34;https://ieeexplore.ieee.org/document/9574030&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Quantum Convolutional Neural Network&lt;/a&gt;, &lt;a href=&#34;https://arxiv.org/abs/2202.11766&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Quantum Natural Language Processing&lt;/a&gt;, etc. M·∫∑c d√π ƒë√£ c√≥ nh·ªØng ch·ª©ng minh cho th·∫•y kh·∫£ nƒÉng QNN c√≥ th·ªÉ gi√∫p gi·∫£m thi·ªÉu s·ªë l∆∞·ª£ng tham s·ªë c·∫ßn ph·∫£i hu·∫•n luy·ªán so v·ªõi NN trong khi v·∫´n ƒë·∫°t ƒë∆∞·ª£c ƒë·ªô ch√≠nh x√°c t∆∞∆°ng ƒë∆∞∆°ng; tuy nhi√™n, c√°c th√≠ nghi·ªám v·∫´n ·ªü tr√™n quy m√¥ nh·ªè v√† c√°c m√¥ h√¨nh NN th∆∞·ªùng b·ªã gi·ªõi h·∫°n ƒë·ªÉ so s√°nh. Do ƒë√≥, QNN v·∫´n ƒëang l√† h∆∞·ªõng ti·∫øp c·∫≠n m·ªü v√† hi·ªán t·∫°i v·∫´n ƒëang thu h√∫t r·∫•t nhi·ªÅu s·ª± ch√∫ √Ω.&lt;/p&gt;
&lt;h2 id=&#34;k·∫øt-lu·∫≠n-a-name3a&#34;&gt;K·∫øt lu·∫≠n &lt;a name=&#34;3&#34;&gt;&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;B√†i vi·∫øt n√†y, m√¨nh ƒë√£ chia s·∫ª qua Quantum Machine Learning l√† g√¨ v√† c≈©ng nh∆∞ l√Ω do ta c·∫ßn suy x√©t t·ªõi ch√∫ng. Cu·ªëi c√πng, m√¨nh tr√¨nh b√†y qua hai h∆∞·ªõng ti·∫øp c·∫≠n ph·ªï bi·∫øn c·ªßa QML: QRAM-based Quantum Machine Learning v√† Quantum Neural Network. Tuy nhi√™n, c√≥ m·ªôt v√†i c√°c h∆∞·ªõng kh√°c m·ªçi ng∆∞·ªùi c√≥ th·ªÉ xem qua: &lt;a href=&#34;https://en.wikipedia.org/wiki/Quantum_annealing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Quantum annealing&lt;/a&gt;, &lt;a href=&#34;https://arxiv.org/pdf/0810.3828.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Quantum-enhanced Reinforcement Learning&lt;/a&gt;, etc. C√≥ th·ªÉ th·∫•y QML tuy l√† m·ªôt lƒ©nh v·ª±c m·ªõi nh∆∞ng ƒë√£ thu h√∫t r·∫•t nhi·ªÅu nghi√™n c·ª©u ·ªü nhi·ªÅu ch·ªß ƒë·ªÅ kh√°c nhau c·ªßa Machine Learning. ·ªû c√°c b√†i vi·∫øt ti·∫øp theo, m√¨nh s·∫Ω c·ªë g·∫Øng tr√¨nh b√†y m·ªôt c√°ch h·ªá th·ªëng ƒë·ªÉ gi√∫p c√°c b·∫°n n·∫Øm r√µ h∆°n c√°c ki·∫øn th·ª©c th√∫ v·ªã n√†y.&lt;/p&gt;
&lt;p&gt;C·∫£m ∆°n m·ªçi ng∆∞·ªùi ƒë√£ ƒë·ªçc b√†i.&lt;/p&gt;
&lt;script src=&#34;https://giscus.app/client.js&#34;
        data-repo=&#34;qmlvietnam/qmlvietnam.github.io&#34;
        data-repo-id=&#34;R_kgDOH833kg&#34;
        data-category=&#34;General&#34;
        data-category-id=&#34;DIC_kwDOH833ks4CRwGU&#34;
        data-mapping=&#34;pathname&#34;
        data-strict=&#34;0&#34;
        data-reactions-enabled=&#34;1&#34;
        data-emit-metadata=&#34;0&#34;
        data-input-position=&#34;bottom&#34;
        data-theme=&#34;light_high_contrast&#34;
        data-lang=&#34;vi&#34;
        crossorigin=&#34;anonymous&#34;
        async&gt;
&lt;/script&gt;&lt;blockquote&gt;
&lt;/blockquote&gt;
</description>
    </item>
    
    <item>
      <title>About</title>
      <link>https://example.com/authors/intro/</link>
      <pubDate>Fri, 30 Sep 2022 00:00:00 +0000</pubDate>
      <guid>https://example.com/authors/intro/</guid>
      <description>&lt;p&gt;Ch√†o m·ªçi ng∆∞·ªùi, c·∫£m ∆°n m·ªçi ng∆∞·ªùi gh√© qua trang blog c·ªßa m√¨nh.&lt;/p&gt;
&lt;p&gt;M√¨nh l√† &lt;a href=&#34;https://www.linkedin.com/in/tuyen-nguyen-905883201/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Nguy·ªÖn Quang Tuy·∫øn&lt;/a&gt;, m√¨nh t·ªët nghi·ªáp ƒë·∫°i h·ªçc ngh√†nh Khoa h·ªçc m√°y t√≠nh t·∫°i tr∆∞·ªùng University of Aizu, Nh·∫≠t B·∫£n. Trong th·ªùi gian l√†m ƒë·ªì √°n t·ªët nghi·ªáp li√™n quan ƒë·∫øn &lt;a href=&#34;https://en.wikipedia.org/wiki/Quantum_machine_learning&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Quantum Machine Learning&lt;/a&gt; (m√¨nh t·∫°m d·ªãch l√† H·ªçc M√°y L∆∞·ª£ng T·ª≠), m√¨nh ƒë√£ c√≥ mong mu·ªën l√†m ra m·ªôt blog c√° nh√¢n vi·∫øt v·ªÅ lƒ©nh v·ª±c n√†y. Do ƒë√≥, d·ª±a theo hai ngu·ªìn c·∫£m h·ª©ng t·ª´ trang &lt;a href=&#34;https://machinelearningcoban.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Machine Learning c∆° b·∫£n&lt;/a&gt; c·ªßa anh V≈© H·ªØu Ti·ªáp v√† &lt;a href=&#34;https://nttuan8.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Deep Learning c∆° b·∫£n&lt;/a&gt; c·ªßa anh Tu·∫•n, m√¨nh t·∫°o trang n√†y v·ªõi hai k·ª≥ v·ªçng. M·ªôt l√† gi√∫p m√¨nh t·ªïng h·ª£p ki·∫øn th·ª©c v·ªÅ Quantum Machine Learning c≈©ng gi√∫p m√¨nh n·∫Øm ch·∫Øc n·ªÅn m√≥ng trong giai ƒëo·∫°n s∆° khai c·ªßa lƒ©nh v·ª±c n√†y. Hai l√† chia s·∫ª c≈©ng nh∆∞ mong mu·ªën t·∫°o ƒë∆∞·ª£c m·ªôt c·ªông ƒë·ªìng c√°c b·∫°n ƒë·ªçc Vi·ªát Nam ti·∫øp c·∫≠n t·ªõi m·ªôt lƒ©nh v·ª±c m·ªõi nh∆∞ng c≈©ng ƒë·∫ßy tri·ªÉn v·ªçng n√†y.&lt;/p&gt;
&lt;p&gt;Trong qu√° tr√¨nh chu·∫©n b·ªã c≈©ng nh∆∞ l√† vi·∫øt b√†i, m√¨nh s·∫Ω c·ªë g·∫Øng √≠t ƒë·ªông ch·∫°m t·ªõi c√°c hi·ªán t∆∞·ª£ng vƒ© m√¥ ·ªü trong th·∫ø gi·ªõi l∆∞·ª£ng t·ª≠ v√† m√¨nh s·∫Ω ƒëi t·ª´ g√≥c nh√¨n c·ªßa m·ªôt computer scientist ch·ª© kh√¥ng ph·∫£i l√† m·ªôt physicist. Nh∆∞ng m√¨nh hi v·ªçng m·ªçi ng∆∞·ªùi ƒë√£ l√†m quen qua c√°c ki·∫øn th·ª©c c∆° b·∫£n c·ªßa ƒê·∫°i S·ªë Tuy·∫øn T√≠nh (v√¨ h·∫ßu h·∫øt c√°c bi·∫øn ƒë·ªïi trong m√°y t√≠nh l∆∞·ª£ng t·ª≠ l√† tuy·∫øn t√≠nh) v√† k·ªπ nƒÉng l·∫≠p tr√¨nh Python (n·∫øu c√≥ th·ªÉ m√¨nh s·∫Ω c·ªë ƒë∆∞a ra c√°c code demo sau c√°c b√†i vi·∫øt ƒë·ªÉ gi√∫p m·ªçi ng∆∞·ªùi hi·ªÉu r√µ ƒë∆∞·ª£c v·∫•n ƒë·ªÅ h∆°n).&lt;/p&gt;
&lt;p&gt;Ngo√†i c√°c b√†i vi·∫øt ·ªü tr√™n &lt;a href=&#34;#posts&#34;&gt;Blogs&lt;/a&gt;, &lt;a href=&#34;#newsletter&#34;&gt;Newsletter&lt;/a&gt; l√† n∆°i m√¨nh c·∫≠p nh·∫≠t nh·ªØng th√¥ng tin m·ªõi nh·∫•t h√†ng th√°ng li√™n quan t·ªõi Quantum Machine Learning (c√°c b√†i b√°o m·ªõi, h·ªôi ngh·ªã, workshop, etc.)&lt;/p&gt;
&lt;p&gt;M√¨nh vui l√≤ng ti·∫øp nh·∫≠n m·ªçi √Ω ki·∫øn th·∫£o lu·∫≠n c·ªßa m·ªçi ng∆∞·ªùi qua email &lt;a href=&#34;mailto:quantummachinelearning.vietnam@gmail.com&#34;&gt;quantummachinelearning.vietnam@gmail.com&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;M√¨nh xin ch√¢n th√†nh c·∫£m ∆°n.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>https://example.com/admin/config.yml</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://example.com/admin/config.yml</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
